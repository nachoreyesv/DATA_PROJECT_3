{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'<NA>':np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0   51    1   1     125.0  213.0  0.0      2.0    125.0    1.0      1.4   \n",
       "1   54    1   3     120.0  237.0  0.0      0.0    150.0    1.0      1.5   \n",
       "2   63    1   4     140.0    0.0  NaN      2.0    149.0    0.0      2.0   \n",
       "3   52    0   2     140.0    NaN  0.0      0.0    140.0    0.0      0.0   \n",
       "4   55    1   4     140.0  217.0  0.0      0.0    111.0    1.0      5.6   \n",
       "\n",
       "   slope   ca  thal  label  \n",
       "0    1.0  1.0   3.0    0.0  \n",
       "1    NaN  NaN   7.0    2.0  \n",
       "2    1.0  NaN   NaN    2.0  \n",
       "3    NaN  NaN   NaN    0.0  \n",
       "4    3.0  0.0   7.0    3.0  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "1    722\n",
       "0    194\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se podría probar a hacer un balanceo de la variable 'sex': \n",
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Definir columnas numéricas y categóricas\n",
    "numeric_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'label']\n",
    "\n",
    "# Convertir '<NA>' a NaN\n",
    "df.replace('<NA>', np.nan, inplace=True)\n",
    "\n",
    "# Convertir columnas numéricas a tipo float\n",
    "df[numeric_cols] = df[numeric_cols].astype(float)\n",
    "\n",
    "# Convertir columnas categóricas a tipo categórico\n",
    "df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "\n",
    "# Imputación para variables numéricas (usando la media)\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Imputación para variables categóricas (usando la moda)\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Verificar que ya no hay valores faltantes\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex  trestbps        chol  fbs  thalach  exang  oldpeak  label  \\\n",
      "0  51.0  1.0     125.0  213.000000  0.0    125.0    1.0      1.4    0.0   \n",
      "1  54.0  1.0     120.0  237.000000  0.0    150.0    1.0      1.5    2.0   \n",
      "2  63.0  1.0     140.0    0.000000  0.0    149.0    0.0      2.0    2.0   \n",
      "3  52.0  0.0     140.0  199.146727  0.0    140.0    0.0      0.0    0.0   \n",
      "4  55.0  1.0     140.0  217.000000  0.0    111.0    1.0      5.6    3.0   \n",
      "\n",
      "   cp_2.0  ...  cp_4.0  restecg_1.0  restecg_2.0  slope_2.0  slope_3.0  \\\n",
      "0   False  ...   False        False         True      False      False   \n",
      "1   False  ...   False        False        False       True      False   \n",
      "2   False  ...    True        False         True      False      False   \n",
      "3    True  ...   False        False        False       True      False   \n",
      "4   False  ...    True        False        False      False       True   \n",
      "\n",
      "   thal_6.0  thal_7.0  ca_1.0  ca_2.0  ca_3.0  \n",
      "0     False     False    True   False   False  \n",
      "1     False      True   False   False   False  \n",
      "2     False     False   False   False   False  \n",
      "3     False     False   False   False   False  \n",
      "4     False      True   False   False   False  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Variables tratadas con one-hot encoding\n",
    "categorical_variables = ['cp', 'restecg', 'slope', 'thal', 'ca']\n",
    "\n",
    "# Aplicar one-hot encoding a las variables categóricas\n",
    "df = pd.get_dummies(df, columns=categorical_variables, drop_first=True)\n",
    "\n",
    "# Mostrar el DataFrame con las variables codificadas\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona solo las características numéricas\n",
    "numeric_data = df[['trestbps', 'chol', 'thalach', 'oldpeak', 'age']]\n",
    "\n",
    "# Inicializa el escalador Min-Max\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Escala las características numéricas\n",
    "scaled_numeric_data = scaler.fit_transform(numeric_data) \n",
    "\n",
    "# Crea un nuevo DataFrame con las características escaladas\n",
    "scaled_data = pd.DataFrame(scaled_numeric_data, columns=['trestbps', 'chol', 'thalach', 'oldpeak', 'age'])\n",
    "\n",
    "# Reemplaza las características originales con las características escaladas en tu DataFrame\n",
    "df[['trestbps', 'chol', 'thalach', 'oldpeak', 'age']] = scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>label</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>restecg_1.0</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>ca_1.0</th>\n",
       "      <th>ca_2.0</th>\n",
       "      <th>ca_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.469388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.353234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.530612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.393035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.330260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.551020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.359867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.359155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex  trestbps      chol  fbs   thalach  exang   oldpeak  label  \\\n",
       "0  0.469388  1.0     0.625  0.353234  0.0  0.457746    1.0  0.454545    0.0   \n",
       "1  0.530612  1.0     0.600  0.393035  0.0  0.633803    1.0  0.465909    2.0   \n",
       "2  0.714286  1.0     0.700  0.000000  0.0  0.626761    0.0  0.522727    2.0   \n",
       "3  0.489796  0.0     0.700  0.330260  0.0  0.563380    0.0  0.295455    0.0   \n",
       "4  0.551020  1.0     0.700  0.359867  0.0  0.359155    1.0  0.931818    3.0   \n",
       "\n",
       "   cp_2.0  ...  cp_4.0  restecg_1.0  restecg_2.0  slope_2.0  slope_3.0  \\\n",
       "0   False  ...   False        False         True      False      False   \n",
       "1   False  ...   False        False        False       True      False   \n",
       "2   False  ...    True        False         True      False      False   \n",
       "3    True  ...   False        False        False       True      False   \n",
       "4   False  ...    True        False        False      False       True   \n",
       "\n",
       "   thal_6.0  thal_7.0  ca_1.0  ca_2.0  ca_3.0  \n",
       "0     False     False    True   False   False  \n",
       "1     False      True   False   False   False  \n",
       "2     False     False   False   False   False  \n",
       "3     False     False   False   False   False  \n",
       "4     False      True   False   False   False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de train y test\n",
    "train_end = df[0:732]\n",
    "test_end = df[(916-184):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo: 0.45108695652173914\n",
      "F1-score del modelo: 0.6217228464419475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Identificar la variable objetivo y las características para el entrenamiento\n",
    "target_column = 'label'  # Nombre real de la variable objetivo\n",
    "features_train = train_end.drop(columns=[target_column])\n",
    "target_train = train_end[target_column]\n",
    "\n",
    "# Identificar las características para la predicción en el conjunto de prueba\n",
    "features_test = test_end.drop(columns=[target_column])\n",
    "\n",
    "# Inicializar el modelo de Random Forest para clasificación con los parámetros especificados\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=10, min_samples_split=5,\n",
    "                               min_samples_leaf=2, max_features=None, random_state=20)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Predecir las clases en el conjunto de prueba\n",
    "predicted_classes = model.predict(features_test)\n",
    "\n",
    "# Crear un nuevo DataFrame con las clases predichas\n",
    "predicted_df = test_end.copy()\n",
    "predicted_df[target_column] = predicted_classes\n",
    "\n",
    "# Calcular el accuracy del modelo\n",
    "accuracy = accuracy_score(test_end[target_column], predicted_classes)\n",
    "print(\"Accuracy del modelo:\", accuracy)\n",
    "\n",
    "# Calcular el F1-score del modelo\n",
    "f1 = f1_score(test_end[target_column], predicted_classes, average='weighted')\n",
    "print(\"F1-score del modelo:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df['index'] = predicted_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# Renombrar la columna 'level_0' a 'index'\n",
    "predicted_df.rename(columns={'level_0': 'index'}, inplace=True)\n",
    "\n",
    "predicted_df['ID'] = range(len(predicted_df))\n",
    "# Guardar las columnas 'index' y 'label' en un archivo CSV\n",
    "predicted_df[['ID', 'label']].to_csv('try1000_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "try1000_df = pd.read_csv('try1000_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    83\n",
       "1.0    43\n",
       "3.0    31\n",
       "2.0    26\n",
       "4.0     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try1000_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "try11_df = pd.read_csv('try11_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "try10_df = pd.read_csv('try10_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores que cambian: 59\n"
     ]
    }
   ],
   "source": [
    "differences = try1000_df['label'].compare(try11_df['label'])\n",
    "differences = differences[differences['self'] != differences['other']]\n",
    "\n",
    "# Calcular la suma de cuántos valores cambian\n",
    "num_differences = differences.shape[0]\n",
    "\n",
    "print(\"Número de valores que cambian:\", num_differences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     self  other\n",
      "0     4.0    2.0\n",
      "7     1.0    2.0\n",
      "8     1.0    3.0\n",
      "16    2.0    3.0\n",
      "17    1.0    2.0\n",
      "27    2.0    3.0\n",
      "30    1.0    3.0\n",
      "39    1.0    2.0\n",
      "40    1.0    0.0\n",
      "50    0.0    2.0\n",
      "54    2.0    1.0\n",
      "57    2.0    1.0\n",
      "59    1.0    0.0\n",
      "60    1.0    2.0\n",
      "61    2.0    1.0\n",
      "69    1.0    0.0\n",
      "73    2.0    3.0\n",
      "84    1.0    2.0\n",
      "90    3.0    0.0\n",
      "94    2.0    0.0\n",
      "95    2.0    3.0\n",
      "97    3.0    2.0\n",
      "98    0.0    1.0\n",
      "101   0.0    1.0\n",
      "107   0.0    1.0\n",
      "109   1.0    0.0\n",
      "112   3.0    1.0\n",
      "113   3.0    0.0\n",
      "115   0.0    1.0\n",
      "116   2.0    1.0\n",
      "119   0.0    1.0\n",
      "122   2.0    3.0\n",
      "125   3.0    1.0\n",
      "138   2.0    3.0\n",
      "142   3.0    0.0\n",
      "145   3.0    2.0\n",
      "148   1.0    3.0\n",
      "153   1.0    3.0\n",
      "154   1.0    3.0\n",
      "164   3.0    1.0\n",
      "170   0.0    1.0\n",
      "172   1.0    0.0\n",
      "175   3.0    2.0\n"
     ]
    }
   ],
   "source": [
    "differences = try600_df['label'].compare(try11_df['label'])\n",
    "differences = differences[differences['self'] != differences['other']]\n",
    "\n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo: 0.532608695652174\n",
      "F1-score del modelo: 0.6950354609929078\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Identificar la variable objetivo y las características para el entrenamiento\n",
    "target_column = 'label'  # Nombre real de la variable objetivo\n",
    "features_train = train_end.drop(columns=[target_column])\n",
    "target_train = train_end[target_column]\n",
    "\n",
    "# Identificar las características para la predicción en el conjunto de prueba\n",
    "features_test = test_end.drop(columns=[target_column])\n",
    "\n",
    "# Definir los hiperparámetros del modelo XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Problema de clasificación multiclase\n",
    "    'num_class': 5,                 # Número de clases\n",
    "    'eval_metric': 'mlogloss',      # Métrica de evaluación para clasificación multiclase\n",
    "    'eta': 0.3,                     # Tasa de aprendizaje\n",
    "    'max_depth': 6,                 # Profundidad máxima del árbol ajustada\n",
    "    'subsample': 0.8,               # Submuestreo de filas\n",
    "    'colsample_bytree': 0.6,        # Submuestreo de columnas\n",
    "    'seed': 42                      # Semilla para reproducibilidad\n",
    "}\n",
    "\n",
    "# Imputar valores faltantes si es necesario\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_train_imputed = imputer.fit_transform(features_train)\n",
    "features_test_imputed = imputer.transform(features_test)\n",
    "\n",
    "# Crear un objeto DMatrix para los datos de entrenamiento y prueba\n",
    "dtrain = xgb.DMatrix(features_train_imputed, label=target_train)\n",
    "dtest = xgb.DMatrix(features_test_imputed)\n",
    "\n",
    "# Entrenar el modelo\n",
    "num_rounds = 75  # Número de rondas de entrenamiento\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Calcular la precisión del modelo (accuracy score)\n",
    "accuracy = accuracy_score(test_end[target_column], y_pred)\n",
    "print(\"Accuracy del modelo:\", accuracy)\n",
    "\n",
    "# Calcular el F1-score del modelo\n",
    "f1 = f1_score(test_end[target_column], y_pred, average='weighted')\n",
    "print(\"F1-score del modelo:\", f1)\n",
    "\n",
    "# Crear un nuevo DataFrame con las clases predichas\n",
    "predicted_df = test_end.copy()\n",
    "predicted_df[target_column] = y_pred\n",
    "\n",
    "# Agregar una columna 'ID' y resetear el índice\n",
    "predicted_df.reset_index(inplace=True)\n",
    "predicted_df['ID'] = range(len(predicted_df))\n",
    "\n",
    "# Eliminar la columna 'index'\n",
    "predicted_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# Guardar las columnas 'ID' y 'label' en un archivo CSV\n",
    "predicted_df[['ID', 'label']].to_csv('try3000_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "try3000_df = pd.read_csv('try3000_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    98\n",
       "1.0    33\n",
       "2.0    29\n",
       "3.0    22\n",
       "4.0     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try3000_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "try700_df = pd.read_csv('try700_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "try800_df = pd.read_csv('try800_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores que cambian: 47\n"
     ]
    }
   ],
   "source": [
    "differences = try700_df['label'].compare(try800_df['label'])\n",
    "differences = differences[differences['self'] != differences['other']]\n",
    "\n",
    "# Calcular la suma de cuántos valores cambian\n",
    "num_differences = differences.shape[0]\n",
    "\n",
    "print(\"Número de valores que cambian:\", num_differences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Identificar la variable objetivo y las características para el entrenamiento\n",
    "# target_column = 'label'  # Nombre real de la variable objetivo\n",
    "# features_train = train_end.drop(columns=[target_column])\n",
    "# target_train = train_end[target_column]\n",
    "\n",
    "# # Identificar las características para la predicción en el conjunto de prueba\n",
    "# features_test = test_end.drop(columns=[target_column])\n",
    "\n",
    "# # Inicializar el modelo de Random Forest para clasificación\n",
    "# model = RandomForestClassifier(random_state=20)\n",
    "\n",
    "# # Definir los hiperparámetros a buscar\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 150],  # Número de árboles en el bosque\n",
    "#     'max_depth': [10, 20, 30],      # Profundidad máxima de los árboles\n",
    "#     'min_samples_split': [2, 5, 10],   # Número mínimo de muestras requeridas para dividir un nodo interno\n",
    "#     'min_samples_leaf': [1, 2, 4],     # Número mínimo de muestras requeridas para ser una hoja\n",
    "#     'max_features': ['sqrt', 'log2', None]  # Número máximo de características consideradas para dividir un nodo\n",
    "# }\n",
    "\n",
    "# # Realizar la búsqueda en cuadrícula con validación cruzada\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "# grid_search.fit(features_train, target_train)\n",
    "\n",
    "# # Obtener el mejor modelo y sus hiperparámetros\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# # Imprimir los mejores hiperparámetros encontrados\n",
    "# print(\"Mejores hiperparámetros encontrados:\")\n",
    "# print(best_params)\n",
    "\n",
    "# # Predecir las clases de las variables categóricas faltantes en el conjunto de prueba\n",
    "# predicted_classes = best_model.predict(features_test)\n",
    "\n",
    "# # Calcular el accuracy del modelo\n",
    "# accuracy = accuracy_score(test_end[target_column], predicted_classes)\n",
    "# print(\"Accuracy del modelo:\", accuracy)\n",
    "\n",
    "# # Calcular el F1-score del modelo\n",
    "# f1 = f1_score(test_end[target_column], predicted_classes, average='weighted')\n",
    "# print(\"F1-score del modelo:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# # Renombrar la columna 'level_0' a 'index'\n",
    "# predicted_df.rename(columns={'level_0': 'index'}, inplace=True)\n",
    "\n",
    "# predicted_df['ID'] = range(len(predicted_df))\n",
    "# # Guardar las columnas 'index' y 'label' en un archivo CSV\n",
    "# predicted_df[['ID', 'label']].to_csv('try500_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try500_df = pd.read_csv('try500_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try500_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import xgboost as xgb\n",
    "\n",
    "# # Dividir los datos en características (X) y variable objetivo (y)\n",
    "# X = df.drop(columns=['label'])  # Características\n",
    "# y = df['label']  # Variable objetivo\n",
    "\n",
    "# # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Definir el número de clases en la variable objetivo\n",
    "# num_classes = len(np.unique(y))\n",
    "\n",
    "# # Crear un objeto DMatrix para los datos de entrenamiento y prueba\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# # Definir los parámetros iniciales del modelo XGBoost\n",
    "# params = {\n",
    "#     'objective': 'multi:softmax',  # Problema de clasificación multiclase\n",
    "#     'eval_metric': 'mlogloss',  # Métrica de evaluación\n",
    "#     'eta': 0.1,  # Tasa de aprendizaje\n",
    "#     'max_depth': 6,  # Profundidad máxima del árbol\n",
    "#     'subsample': 0.8,  # Submuestreo de filas\n",
    "#     'colsample_bytree': 0.8,  # Submuestreo de columnas\n",
    "#     'seed': 42,  # Semilla para reproducibilidad\n",
    "#     'num_class': num_classes  # Número de clases en la clasificación multiclase\n",
    "# }\n",
    "\n",
    "# # Definir los hiperparámetros a buscar en la cuadrícula\n",
    "# param_grid = {\n",
    "#     'eta': [0.01, 0.1, 0.3],  # Tasa de aprendizaje\n",
    "#     'max_depth': [3, 6, 9],  # Profundidad máxima del árbol\n",
    "#     'subsample': [0.6, 0.8, 1.0],  # Submuestreo de filas\n",
    "#     'colsample_bytree': [0.6, 0.8, 1.0]  # Submuestreo de columnas\n",
    "# }\n",
    "\n",
    "# # Inicializar el clasificador XGBoost\n",
    "# xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=num_classes, seed=42)\n",
    "\n",
    "# # Realizar búsqueda en cuadrícula\n",
    "# grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='f1_weighted', verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Obtener los mejores hiperparámetros encontrados\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Mejores hiperparámetros encontrados:\", best_params)\n",
    "\n",
    "# # Entrenar el modelo con los mejores hiperparámetros encontrados\n",
    "# best_model = grid_search.best_estimator_\n",
    "# best_model.fit(X_train, y_train)\n",
    "\n",
    "# # Realizar predicciones en el conjunto de prueba\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# # Calcular la precisión del modelo (accuracy score)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Precisión del modelo:\", accuracy)\n",
    "\n",
    "# # Calcular el F1-score del modelo\n",
    "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "# print(\"El F1-score del modelo es:\", f1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
