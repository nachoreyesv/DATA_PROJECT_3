{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza y transformación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'<NA>':np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir columnas numéricas y categóricas\n",
    "numeric_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal', 'label']\n",
    "\n",
    "# Convertir '<NA>' a NaN\n",
    "df.replace('<NA>', np.nan, inplace=True)\n",
    "\n",
    "# Convertir 0.0 a NaN en la columna \"chol\"\n",
    "df['chol'] = df['chol'].replace(0.0, np.nan)\n",
    "\n",
    "# Reemplazar los valores 0.0 y los valores negativos por NaN en la columna 'oldpeak'\n",
    "df['oldpeak'] = np.where((df['oldpeak'] <= 0), np.nan, df['oldpeak'])\n",
    "\n",
    "# Convertir columnas numéricas a tipo float\n",
    "df[numeric_cols] = df[numeric_cols].astype(float)\n",
    "\n",
    "# Convertir columnas categóricas a tipo categórico\n",
    "df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "\n",
    "# Imputación para variables numéricas (usando la media)\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Imputación para variables categóricas (usando la moda)\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Verificar que ya no hay valores faltantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables tratadas con one-hot encoding\n",
    "categorical_variables = ['cp', 'restecg', 'slope', 'thal', 'ca']\n",
    "\n",
    "# Aplicar one-hot encoding a las variables categóricas\n",
    "df = pd.get_dummies(df, columns=categorical_variables, drop_first=True)\n",
    "\n",
    "# Mostrar el DataFrame con las variables codificadas\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona solo las características numéricas\n",
    "numeric_data = df[['trestbps', 'chol', 'thalach', 'oldpeak', 'age']]\n",
    "\n",
    "# Inicializa el escalador Min-Max\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Escala las características numéricas\n",
    "scaled_numeric_data = scaler.fit_transform(numeric_data) \n",
    "\n",
    "# Crea un nuevo DataFrame con las características escaladas\n",
    "scaled_data = pd.DataFrame(scaled_numeric_data, columns=['trestbps', 'chol', 'thalach', 'oldpeak', 'age'])\n",
    "\n",
    "# Reemplaza las características originales con las características escaladas en tu DataFrame\n",
    "df[['trestbps', 'chol', 'thalach', 'oldpeak', 'age']] = scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de train y test\n",
    "train_end = df[0:732]\n",
    "test_end = df[(916-184):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBAS DE LOS MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 TRY - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Identificar la variable objetivo y las características para el entrenamiento\n",
    "target_column = 'label'  # Nombre real de la variable objetivo\n",
    "features_train = train_end.drop(columns=[target_column])\n",
    "target_train = train_end[target_column]\n",
    "\n",
    "# Identificar las características para la predicción en el conjunto de prueba\n",
    "features_test = test_end.drop(columns=[target_column])\n",
    "\n",
    "# Inicializar y entrenar el modelo de Random Forest para clasificación\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Predecir las clases de las variables categóricas faltantes en el conjunto de prueba\n",
    "predicted_classes = model.predict(features_test)\n",
    "\n",
    "# Crear un nuevo DataFrame con las clases predichas\n",
    "predicted_df = test_end.copy()\n",
    "predicted_df[target_column] = predicted_classes\n",
    "\n",
    "# Imprimir el DataFrame con las clases predichas\n",
    "print(predicted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df['index'] = predicted_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# Renombrar la columna 'level_0' a 'index'\n",
    "predicted_df.rename(columns={'level_0': 'index'}, inplace=True)\n",
    "\n",
    "predicted_df['ID'] = range(len(predicted_df))\n",
    "# Guardar las columnas 'index' y 'label' en un archivo CSV\n",
    "predicted_df[['ID', 'label']].to_csv('try4_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try4_df = pd.read_csv('try4_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try4_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 TRY - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Crear un modelo de clasificador SVM\n",
    "svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', C=1.0, random_state=42))\n",
    "\n",
    "# Entrenar el modelo SVM\n",
    "svm_model.fit(features_train, target_train)\n",
    "\n",
    "# Predecir las clases en el conjunto de prueba\n",
    "predicted_classes_svm = svm_model.predict(features_test)\n",
    "\n",
    "# Crear un nuevo DataFrame con las clases predichas por SVM\n",
    "predicted_df_svm = test_end.copy()\n",
    "predicted_df_svm[target_column] = predicted_classes_svm\n",
    "\n",
    "# Imprimir el DataFrame con las clases predichas por SVM\n",
    "print(predicted_df_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_svm['index'] = predicted_df.index\n",
    "predicted_df_svm.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_svm.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# Renombrar la columna 'level_0' a 'index'\n",
    "predicted_df_svm.rename(columns={'level_0': 'index'}, inplace=True)\n",
    "\n",
    "predicted_df_svm['ID'] = range(len(predicted_df_svm))\n",
    "# Guardar las columnas 'index' y 'label' en un archivo CSV\n",
    "predicted_df_svm[['ID', 'label']].to_csv('try5_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try5_df = pd.read_csv('try5_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try5_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 TRY - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fue un error de try, se me olvidó escalar la edad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 TRY - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Identificar la variable objetivo y las características para el entrenamiento\n",
    "target_column = 'label'  # Nombre real de la variable objetivo\n",
    "features_train = train_end.drop(columns=[target_column])\n",
    "target_train = train_end[target_column]\n",
    "\n",
    "# Identificar las características para la predicción en el conjunto de prueba\n",
    "features_test = test_end.drop(columns=[target_column])\n",
    "\n",
    "# Inicializar y entrenar el modelo de Random Forest para clasificación\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Predecir las clases de las variables categóricas faltantes en el conjunto de prueba\n",
    "predicted_classes = model.predict(features_test)\n",
    "\n",
    "# Crear un nuevo DataFrame con las clases predichas\n",
    "predicted_df = test_end.copy()\n",
    "predicted_df[target_column] = predicted_classes\n",
    "\n",
    "# Imprimir el DataFrame con las clases predichas\n",
    "print(predicted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df['index'] = predicted_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# Renombrar la columna 'level_0' a 'index'\n",
    "predicted_df.rename(columns={'level_0': 'index'}, inplace=True)\n",
    "\n",
    "predicted_df['ID'] = range(len(predicted_df))\n",
    "# Guardar las columnas 'index' y 'label' en un archivo CSV\n",
    "predicted_df[['ID', 'label']].to_csv('try44_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try44_df = pd.read_csv('try44_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try44_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variable chol\n",
    "chol_values = df['chol']\n",
    "\n",
    "# Crear el histograma\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(chol_values, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribución de la variable \"chol\"')\n",
    "plt.xlabel('Valor')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 TRY - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir '<NA>' a NaN\n",
    "df.replace('<NA>', np.nan, inplace=True)\n",
    "\n",
    "# Obtener columnas numéricas y categóricas\n",
    "numeric_cols_mean = ['trestbps', 'thalach', 'chol']\n",
    "numeric_cols_median = ['oldpeak', 'age']\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal', 'label', 'ca']\n",
    "\n",
    "# Imputación para variables numéricas con la media\n",
    "numeric_imputer_mean = SimpleImputer(strategy='mean')\n",
    "df[numeric_cols_mean] = numeric_imputer_mean.fit_transform(df[numeric_cols_mean])\n",
    "\n",
    "# Imputación para variables numéricas con la mediana\n",
    "numeric_imputer_median = SimpleImputer(strategy='median')\n",
    "df[numeric_cols_median] = numeric_imputer_median.fit_transform(df[numeric_cols_median])\n",
    "\n",
    "# Imputación para variables categóricas (usando la moda)\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Verificar que ya no hay valores faltantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17 TRY - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir '<NA>' a NaN\n",
    "df.replace('<NA>', np.nan, inplace=True)\n",
    "\n",
    "# Obtener columnas numéricas y categóricas\n",
    "numeric_cols_mean = ['trestbps', 'thalach', 'age']\n",
    "numeric_cols_median = ['oldpeak', 'chol']\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal', 'label', 'ca']\n",
    "\n",
    "# Imputación para variables numéricas con la media\n",
    "numeric_imputer_mean = SimpleImputer(strategy='mean')\n",
    "df[numeric_cols_mean] = numeric_imputer_mean.fit_transform(df[numeric_cols_mean])\n",
    "\n",
    "# Imputación para variables numéricas con la mediana\n",
    "numeric_imputer_median = SimpleImputer(strategy='median')\n",
    "df[numeric_cols_median] = numeric_imputer_median.fit_transform(df[numeric_cols_median])\n",
    "\n",
    "# Imputación para variables categóricas (usando la moda)\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Verificar que ya no hay valores faltantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18 TRY - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir '<NA>' a NaN\n",
    "df.replace('<NA>', np.nan, inplace=True)\n",
    "\n",
    "# Obtener columnas numéricas y categóricas\n",
    "numeric_cols_mean = ['trestbps', 'thalach', 'age', 'chol']\n",
    "numeric_cols_median = ['oldpeak']\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal', 'label', 'ca']\n",
    "\n",
    "# Imputación para variables numéricas con la media\n",
    "numeric_imputer_mean = SimpleImputer(strategy='mean')\n",
    "df[numeric_cols_mean] = numeric_imputer_mean.fit_transform(df[numeric_cols_mean])\n",
    "\n",
    "# Imputación para variables numéricas con la mediana\n",
    "numeric_imputer_median = SimpleImputer(strategy='median')\n",
    "df[numeric_cols_median] = numeric_imputer_median.fit_transform(df[numeric_cols_median])\n",
    "\n",
    "# Imputación para variables categóricas (usando la moda)\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Verificar que ya no hay valores faltantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21 TRY - XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X_train = train_end.drop(columns=['label'])\n",
    "y_train = train_end['label']\n",
    "X_test = test_end.drop(columns=['label'])\n",
    "y_test = test_end['label']\n",
    "\n",
    "# Convertir los datos al formato DMatrix requerido por XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Definir los parámetros del modelo XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Multiclass classification\n",
    "    'num_class': len(df['label'].unique()),  # Número de clases\n",
    "    'max_depth': 6,  # Profundidad máxima del árbol\n",
    "    'eta': 0.3,  # Tasa de aprendizaje\n",
    "    'subsample': 0.8,  # Submuestreo de filas\n",
    "    'colsample_bytree': 0.8,  # Submuestreo de columnas\n",
    "    'eval_metric': 'merror'  # Métrica de evaluación\n",
    "}\n",
    "\n",
    "# Entrenar el modelo XGBoost\n",
    "num_round = 100  # Número de rondas de entrenamiento\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión del modelo XGBoost:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
